{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a25abd61-6a0d-4947-bfed-15eaa5181e05",
   "metadata": {},
   "source": [
    "# Ollama Local"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae80660-17ce-4465-9cbd-2e42a0162b47",
   "metadata": {},
   "source": [
    "## Primeiros passos:\n",
    "\n",
    "- Instale o ollama em seu computador e baixe uma llm de sua preferencia(https://github.com/ollama/ollama);\n",
    "\n",
    "- Assim que estiver rodando a LLM siga este passos, instalando as dependencias abaixo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cffa400a-ea3d-46d1-9c21-3ac34951f226",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama-index-llms-ollama in c:\\users\\patrick\\anaconda3\\lib\\site-packages (0.5.0)\n",
      "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.4 in c:\\users\\patrick\\anaconda3\\lib\\site-packages (from llama-index-llms-ollama) (0.12.5)\n",
      "Requirement already satisfied: ollama>=0.4.3 in c:\\users\\patrick\\anaconda3\\lib\\site-packages (from llama-index-llms-ollama) (0.4.4)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in c:\\users\\patrick\\anaconda3\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in c:\\users\\patrick\\anaconda3\\lib\\site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (2.0.34)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in c:\\users\\patrick\\anaconda3\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (3.10.5)\n",
      "Requirement already satisfied: dataclasses-json in c:\\users\\patrick\\anaconda3\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in c:\\users\\patrick\\anaconda3\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (1.2.15)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in c:\\users\\patrick\\anaconda3\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (1.0.8)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in c:\\users\\patrick\\anaconda3\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (1.2.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\patrick\\anaconda3\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (2024.6.1)\n",
      "Requirement already satisfied: httpx in c:\\users\\patrick\\anaconda3\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (0.27.0)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in c:\\users\\patrick\\appdata\\roaming\\python\\python312\\site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in c:\\users\\patrick\\anaconda3\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (3.3)\n",
      "Requirement already satisfied: nltk>3.8.1 in c:\\users\\patrick\\anaconda3\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (3.9.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\patrick\\anaconda3\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (1.26.4)\n",
      "Requirement already satisfied: pillow>=9.0.0 in c:\\users\\patrick\\anaconda3\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (10.4.0)\n",
      "Requirement already satisfied: pydantic>=2.8.0 in c:\\users\\patrick\\anaconda3\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (2.10.3)\n",
      "Requirement already satisfied: requests>=2.31.0 in c:\\users\\patrick\\anaconda3\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in c:\\users\\patrick\\anaconda3\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (8.2.3)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in c:\\users\\patrick\\anaconda3\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (0.8.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in c:\\users\\patrick\\anaconda3\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\patrick\\anaconda3\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (4.12.2)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in c:\\users\\patrick\\anaconda3\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (0.9.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\patrick\\anaconda3\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (1.14.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\patrick\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\patrick\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\patrick\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\patrick\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\patrick\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\patrick\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (1.11.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\patrick\\anaconda3\\lib\\site-packages (from httpx->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (4.2.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\patrick\\anaconda3\\lib\\site-packages (from httpx->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\patrick\\anaconda3\\lib\\site-packages (from httpx->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (1.0.2)\n",
      "Requirement already satisfied: idna in c:\\users\\patrick\\anaconda3\\lib\\site-packages (from httpx->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (3.7)\n",
      "Requirement already satisfied: sniffio in c:\\users\\patrick\\anaconda3\\lib\\site-packages (from httpx->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\patrick\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (0.14.0)\n",
      "Requirement already satisfied: click in c:\\users\\patrick\\anaconda3\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\patrick\\anaconda3\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\patrick\\anaconda3\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (2024.9.11)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\patrick\\anaconda3\\lib\\site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in c:\\users\\patrick\\anaconda3\\lib\\site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (2.27.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\patrick\\anaconda3\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\patrick\\anaconda3\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (2.2.3)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\patrick\\anaconda3\\lib\\site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (3.0.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\patrick\\appdata\\roaming\\python\\python312\\site-packages (from tqdm<5.0.0,>=4.66.1->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (0.4.6)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\patrick\\anaconda3\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\patrick\\anaconda3\\lib\\site-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (3.23.1)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\users\\patrick\\anaconda3\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (24.1)\n"
     ]
    }
   ],
   "source": [
    "! pip install llama-index-llms-ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f68ad3e-6c21-4926-a3e9-a145471073f1",
   "metadata": {},
   "source": [
    "Agora vamos carregar a framework neste caso estarei usando o \"llama3.2\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb754816-d19f-4a36-a79a-bfa60f29aacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.ollama import Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef900e75-f449-4781-ae89-e2b0bc6b3aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Ollama(model=\"llama3.2\", request_timeout=120.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e6330a-b8cb-49d0-bb08-3670f71ace31",
   "metadata": {},
   "source": [
    "Agora vamos armazenar a resposta em uma variavel para então nos exibir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29986032-d155-47f3-9992-9108be83250d",
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = llm.complete(\"Quem foi Paul Graham?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c324b53-64e8-4a09-a91d-eb6b05abb4d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paul Graham é um empreendedor, programador e filósofo americano. Ele é mais conhecido por fundar a Y Combinator, uma das principais acelerações de startups do mundo.\n",
      "\n",
      "Graham nasceu em 1959 na Pensilvânia, EUA, e estudou matemática no Harvard College. Depois de se formar, ele trabalhou como programador para várias empresas, incluindo o IBM.\n",
      "\n",
      "Em 1995, Graham co-fundou a Y Combinator com Robert Karp e Marc Andreessen. A aceleração foi projetada para investir em startups de tecnologia com potencial para crescer rapidamente. Graham é conhecido por sua abordagem inovadora e agressiva em relação às startups, que inclui uma rotina de avaliação rigorosa e um período de treinamento intensivo.\n",
      "\n",
      "Graham também é autor de vários livros sobre empreendedorismo e tecnologia, incluindo \"Art of Hardware\" e \"Hackers & Company\". Ele é considerado um dos principais pensadores sobre a inovação e o empreendedorismo modernos.\n",
      "\n",
      "Algumas de suas ideias mais conhecidas incluem:\n",
      "\n",
      "* A importância da \"cultura de startup\" para o sucesso das empresas\n",
      "* A necessidade de equipes de inovação que sejam flexíveis e adaptáveis\n",
      "* O papel da experiência pessoal no desenvolvimento de habilidades empreendedoras\n",
      "\n",
      "Em resumo, Paul Graham é uma figura influente na comunidade de empreendedorismo e tecnologia, conhecido por sua abordagem inovadora e agressiva em relação às startups.\n"
     ]
    }
   ],
   "source": [
    "print(resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684d4a87-0875-4a3f-86e5-7e4a5a58855d",
   "metadata": {},
   "source": [
    "## Sucesso\n",
    "\n",
    "Primeiros passos concluidos temos nossas primeira resposta gerada por uma LLm totalmente local;\n",
    "lembrando cada llm existe uma serie de parâmetros aonde foi treinada, escolha a melhor conforme seu\n",
    "hardware disponivel e seu objetivo;\n",
    "Neste link consiguira explorar cada modelo e sua base de treinamento conseguindo explorar seus recursos;\n",
    "(https://ollama.com/search)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769b3d69-88e4-4062-a508-b53c58573b82",
   "metadata": {},
   "source": [
    "## Agora o que fazer\n",
    "\n",
    "Vamos refinar um pouco mais as resposta, cabendo a você a explorar esta ideia na sua utilização;\n",
    "Por exemplo um pesonalidade:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e2046cc-2f2a-47a3-8d44-c069eb5566db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.llms import ChatMessage\n",
    "\n",
    "messages = [\n",
    "    ChatMessage(\n",
    "        role=\"system\", content=\"Seja um vendedor rabugento de carros e tente vender um tesla no valor de 50 mil reais\"\n",
    "    ),\n",
    "    ChatMessage(role=\"user\", content=\"Olá gostaria de saber mais sobre os carros disponiveis\"),\n",
    "]\n",
    "resp = llm.chat(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "518b074e-8037-4753-8892-bbf81b9077f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assistant: Claro que sim! Vamos falar sobre o nosso carro da estrela, o Tesla!\n",
      "\n",
      "Este é um carro incrível, não é? Com tecnologia avançada e design moderno, é a escolha perfeita para quem busca inovação e sustentabilidade no seu veículo.\n",
      "\n",
      "Vamos começar pelo que faz deste carro especial: a bateria. Este é o coração do Tesla, permitindo que você consiga mais de 500 quilômetros de autonomia, sem precisar parar para reabastecer! E com nossa tecnologia de recarga rápida, você pode esticar a vida da sua bateria em apenas 30 minutos.\n",
      "\n",
      "E não podemos esquecer do design! Este é um carro que vai te deixar impressionado com seu estilo e sofisticação. Com linhas curvas e formas modernas, este carro é uma verdadeira obra de arte.\n",
      "\n",
      "Mas o que realmente faz deste carro especial é a sua tecnologia de propulsão elétrica. Sem emissões, sem ruído, mas com mais de 500 quilômetros de autonomia! É a combinação perfeita para quem busca uma experiência de condução mais suave e sustentável.\n",
      "\n",
      "E agora, vamos falar sobre as especificações:\n",
      "\n",
      "* Motor: Três opções de motor, incluindo uma opção de dupla-turbo que dará 1.020 CV\n",
      "* Autonomia: Mais de 500 quilômetros com a bateria padrão\n",
      "* Velocidade: De 0 a 100 km/h em apenas 2,5 segundos!\n",
      "* Comprimento: 4,800 mm\n",
      "* Largura: 1,920 mm\n",
      "* Altura: 1,400 mm\n",
      "\n",
      "E o que você está pensando? Você está pronto para se juntar à revolução elétrica?\n",
      "\n",
      "Este carro é disponível em três opções de cor: preto, prata e azul. E como oferecemos uma garantia de 5 anos ou 100.000 km, você pode ter certeza de que este é o carro certo para você.\n",
      "\n",
      "O preço do carro é de R$ 50.000,00, mas como estamos oferecendo um desconto especial para os clientes novos, podemos negociar o preço e oferecer R$ 45.000,00! E se você decidir comprar mais de um carro, eu posso oferecer ainda mais descontos!\n",
      "\n",
      "Então, o que você diz? Você está pronto para se juntar à família Tesla?\n"
     ]
    }
   ],
   "source": [
    "print(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "250a945e-a363-48ca-ac09-b62cc8fe468f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ou na chamada específica\n",
    "response = llm.stream_complete(\"Quem é Paul Graham?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9f488522-86a0-4dc6-9c57-56411b1d989b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paul Graham é um empresário e investidor americano, conhecido por ser o fundador da Y Combinator, uma incubadora de startups que ajudou a criar algumas das empresas mais bem-sucedidas do mundo.\n",
      "\n",
      "Graham nasceu em 1964 em Santa Cruz, Califórnia. Ele estudou na Universidade de Harvard e mais tarde se mudou para a Bahrein, onde trabalhou como engenheiro de computador. Em 1999, ele fundou a Y Combinator, que foi inicialmente chamada de \"Founders Fund\". A incubadora rapidamente ganhou reconhecimento por ajudar startups a criar e vender suas ideias.\n",
      "\n",
      "A Y Combinator é conhecida por sua abordagem inovadora e focada em resultados. Ela oferece aos fundadores de startups uma oportunidade para trabalhar com um equipo experiente, receber orientação e financiamento, e entrar no programa do incubador. Em troca, os fundadores devem entregar uma parcela dos ações da empresa à Y Combinator.\n",
      "\n",
      "Durante sua carreira, Graham investiu em várias startups bem-sucedidas, incluindo Airbnb, Reddit, Dropbox, e Cruise (da General Motors). Ele também é um defensor da ideia de que as empresas devem ser mais ágeis e flexíveis, e que os fundadores devem ter mais controle sobre suas empresas.\n",
      "\n",
      "Graham é conhecido por sua visão para o futuro das empresas e seu foco em criar oportunidades para startups emergentes. Ele também é um autor e palestrante popular, tendo publicado vários artigos e capítulos em livros sobre inovação e liderança empresarial.\n",
      "\n",
      "Em resumo, Paul Graham é um empresário e investidor americano que é conhecido por fundar a Y Combinator, uma incubadora de startups que ajudou a criar algumas das empresas mais bem-sucedidas do mundo. Ele é também um defensor da ideia de que as empresas devem ser mais ágeis e flexíveis, e que os fundadores devem ter mais controle sobre suas empresas."
     ]
    }
   ],
   "source": [
    "for r in response:\n",
    "    print(r.delta, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2552b3f-1ec0-417d-95a0-0a55a857dea6",
   "metadata": {},
   "source": [
    "## O que podemos criar?\n",
    "Abaixo uma utilização par criar um \"Analista de dados\" para interpretar os dados em uma variavel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2e92b655-ad5f-495b-8162-aba2c1a273b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d5bc984f-098e-438e-8708-f09ddc664764",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dados_pacientes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3bf0259e-f681-4248-9113-448ca7cd0a00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_paciente</th>\n",
       "      <th>idade(anos)</th>\n",
       "      <th>altura(cm)</th>\n",
       "      <th>peso(kg)</th>\n",
       "      <th>tipo_sanguineo</th>\n",
       "      <th>estado_civil</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>69</td>\n",
       "      <td>206</td>\n",
       "      <td>119</td>\n",
       "      <td>O+</td>\n",
       "      <td>Solteiro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>184</td>\n",
       "      <td>48</td>\n",
       "      <td>AB-</td>\n",
       "      <td>Solteiro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>89</td>\n",
       "      <td>192</td>\n",
       "      <td>48</td>\n",
       "      <td>AB-</td>\n",
       "      <td>Solteiro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>78</td>\n",
       "      <td>205</td>\n",
       "      <td>41</td>\n",
       "      <td>A-</td>\n",
       "      <td>Casado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>38</td>\n",
       "      <td>192</td>\n",
       "      <td>145</td>\n",
       "      <td>A-</td>\n",
       "      <td>Casado</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_paciente  idade(anos)  altura(cm)  peso(kg) tipo_sanguineo estado_civil\n",
       "0            1           69         206       119             O+     Solteiro\n",
       "1            2           32         184        48            AB-     Solteiro\n",
       "2            3           89         192        48            AB-     Solteiro\n",
       "3            4           78         205        41             A-       Casado\n",
       "4            5           38         192       145             A-       Casado"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "69784aca-e81b-4bf8-97e0-dcb7c908f8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crie uma diconário com as porcentagem de cada tipo sanguineo\n",
    "porcentagem_sanguineo = df['tipo_sanguineo'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d2c83c01-2dee-4103-97d9-51751ac81bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.llms import ChatMessage\n",
    "\n",
    "messages = [\n",
    "    ChatMessage(\n",
    "        role=\"system\", content=\"seja um analista de dados especializado em dados, resuma a apenas dados necessários sem explicação, contendo valores e de cada tipagem \"\n",
    "    ),\n",
    "    ChatMessage(role=\"user\", content= \n",
    "                f\"Me explique a variavel {porcentagem_sanguineo}\"),\n",
    "]\n",
    "resp = llm.chat(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d934c446-2702-4baf-91d3-667f2430ee7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assistant: A variável `tipo_sanguineo` parece ter sido categorizada como tipo sanguíneo (doente) com valores numéricos associados a cada tipo.\n",
      "\n",
      "Os valores podem ser resumidos da seguinte forma:\n",
      "\n",
      "- **Tipo A+**: 0.146\n",
      "- **Tipo B+**: 0.136\n",
      "- **Tipo AB+**: 0.128\n",
      "- **Tipo A-**: 0.122\n",
      "- **Tipo O+**: 0.119\n",
      "- **Tipo AB-**: 0.119\n",
      "- **Tipo O-**: 0.118\n",
      "- **Tipo B-**: 0.112\n",
      "\n",
      "Esses valores parecem representar uma medida ou um índice de algo relacionado a cada tipo sanguíneo, mas sem mais informações é difícil determinar exatamente o que esses números representam.\n"
     ]
    }
   ],
   "source": [
    "print(resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2889320-9daa-4dd1-a839-320edd67ad5d",
   "metadata": {},
   "source": [
    "## Agente\n",
    "\n",
    "Criando um Agente vendedor.\n",
    "Vamos criar uma variavel com as informações do carro que queremos vender."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83defb15-f3b2-48bf-9be9-2b9103095ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "estoque = {\n",
    "    \"modelo\": \"CITRÖEN DS3 1.6 TURBO\",\n",
    "    \"descricao\": \"Citroen Ds3 1.6 Turbo 165 m6\",\n",
    "    \"valor\": 52990.00,\n",
    "    \"bancos_financiamento\": [\"Bradesco\", \"Santander\", \"BV Financeira\"], #até 60 veszes\n",
    "    \"detalhes\": [\n",
    "        \"Top de Linha\",\n",
    "        \"Completo\",\n",
    "        \"Ano: 2013\",\n",
    "        \"Modelo: Turbo 165 m6\",\n",
    "        \"Km: 115000\",\n",
    "        \"Câmbio Manual\",\n",
    "        \"Turbo de fábrica\",\n",
    "        \"Ar condicionado\",\n",
    "        \"Direção Elétrica\",\n",
    "        \"Vidros Elétricos\",\n",
    "        \"Retrovisor Elétrico\",\n",
    "        \"Computador de Bordo\",\n",
    "        \"Farol de Milha\",\n",
    "        \"Rodas de Liga\",\n",
    "        \"4 Pneus Semi-Novos\"\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74cbbfe9-d60c-469e-88b8-bfd581146111",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from llama_index.core.llms import ChatMessage\n",
    "\n",
    "def chat_com_llm():\n",
    "    mensagens_historico = [\n",
    "        ChatMessage(\n",
    "            role=\"system\", \n",
    "            content=f\"venda somente o que há em estoque, não de opções, e somente venda o citroen. Não feche a venda e se perguntar sobre o valor apenas fale o valor total do carro e em seguida pegue o contato do cliente.Você é um vendedor profissional da A Carros Multimarcas, especializado em vendas eficiente e personalizado. Siga rigorosamente estas etapas e diretrizes\"\n",
    "    )\n",
    "]\n",
    "\n",
    "    print(\"Bem vindo A Carros multimarcas\")\n",
    "    print(\"Este é um chat totalmente gerado por IA\")\n",
    "    print(\"Digite 'sair' a qualquer momento para encerrar.\")\n",
    "\n",
    "    while True:\n",
    "        # Solicitar entrada do usuário\n",
    "        entrada_usuario = input(\"\\nO que deseja: \")\n",
    "        print(\"Aguarde um momento!\")\n",
    "\n",
    "        # Verificar condição de saída\n",
    "        if entrada_usuario.lower() == 'sair':\n",
    "            print(\"Encerrando o chat. Até logo!\")\n",
    "            break\n",
    "\n",
    "        # Adicionar mensagem do usuário ao histórico\n",
    "        mensagens_historico.append(\n",
    "            ChatMessage(role=\"user\", content=f\"no maximo uma frase me responda:{entrada_usuario}.com base no estoque{estoque}\")\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            # Realizar a chamada para o LLM\n",
    "            resp = llm.chat(mensagens_historico)\n",
    "\n",
    "            # Imprimir resposta\n",
    "            print(\"\\nVendedor:\")\n",
    "            print(resp.message.content)\n",
    "\n",
    "            # Adicionar resposta do LLM ao histórico\n",
    "            mensagens_historico.append(\n",
    "                ChatMessage(role=\"assistant\", content=resp.message.content)\n",
    "            )\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Ocorreu um erro: {e}\")\n",
    "\n",
    "# Chamar a função para iniciar o chat\n",
    "chat_com_llm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600c9450-6ef0-4bba-96be-17bcd4223951",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
